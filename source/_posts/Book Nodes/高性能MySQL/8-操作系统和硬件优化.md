---
title: MySQL操作系统和硬件优化

categories: 

- MySQL

tags: 

- MySQL
date: 2020-12-29 09:48:07
---

### 1.什么限制了MySQL的性能
____

最常见的两个瓶颈是CPU和IO资源。当数据可以放在内存中或者可以从磁盘中以足够块的速度读取时，CPU可能出现瓶颈。把大量的数据完全放到大容量的内存中，以现在的硬件条件是完全可行的。

另一方面，IO瓶颈，一般发生在工作所需的数据远远超过有效内存容量的时候。如果应用程序是分布在网络上的，如果有大量的查询和低延迟的要求，瓶颈可能转移到网络上，而不再是磁盘IO。

#### 2 如何为MySQL选择CPU
_____

档升级或者购买硬件的时候，应当考虑下工作负载是不是CPU密集型。可以通过CPU利用率来判断是否是CPU密集型的工作负载，但是仅看CPU整体的负载是不合理的，还需要看看CPU使用率和大多数重要的查询的IO的平衡，并注意CPU负载是否均匀分配。

##### 2.1 哪个更好，更快的CPU还是更多的CPU
_____

当遇到CPU密集型的工作时,MySQL通常可以从更快的CPU中获益。但这不是绝对的，因为还依赖于负载情况和CPU数量。古老的MySQL在多CPU上有扩展性问题，即使新版本也不能对单个查询并发利用多个CPU。因此，CPU速度限制了每个CPU密集型查询的响应时间。

调优服务器的目标：

- 低延时（快速响应）

    要做到这一点，需要高速CPU，因为每个查询只能使用一个CPU。

- 高吞吐

    如果能同时运行很多查询语句，则可以从多个CPU处理查询中受益。然后，实践中，取决于具体情况。因为MySQL还不能再多个CPU中完美扩展，能用多少CPU是有极限的。不过新版本可以。

MySQL复制也能在高速CPU下工作的很好，而多CPU对复制的帮助不大。如果工作负载是CPU密集型，主库上的并发任务传递到备库以后会被简化为串行任务，这样即使备库硬件比主库好，也可能无法保持跟主库之间的同步。也就是说，备库的瓶颈通常是IO子系统，而不是CPU。

如果有一个CPU密集型的工作负载，考虑是需要更快的CPU还是更多CPU的另外一个因素是查询语句实际在做什么。在硬件层面，一个查询可以在执行或等待。处于等待状态常见的原因是在运行队列中等待（进程已经是可运行状态，但所有的CPU都忙）、等待闩锁（Latch）或锁（Lock）、等待磁盘或网络。那么你期望查询是等待什么呢？如果等待闩锁或锁，通常需要更快的CPU；如果在运行队列中等待，那么更多或者更快的CPU都有可能有帮助。（也有可能例外，例如，查询等待InnoDB日志缓冲区的mutex，直到IO完成前都不会释放，这可能表型需要更多的IO容量）。

这就是说，MySQL在某些工作负载下可以有效地利用很多CPU。例如，假设有很多连接查询的是不同表（假设这些查询不会造成表锁的竞争，实际上对myisam和memory表可能会有问题），并且副武器的总吞吐量比任何单个查询的响应时间都更重要。吞吐量在这种情况下可以非常高，因为线程可以同时运行而互不争用。

再次说明，在理论上这可能更好的工作：不管查询是读取不同的表还是相同的表，InnoDB都会有一些全局共享的数据结构，而myisam在每个缓冲区都有全局所。而且不仅仅是存储引擎，服务器层也会有全局所。以前InnoDB承担了所有的骂名，但最近做了一些改进后，暴露了服务器层中的其他瓶颈。例如臭名昭著的lock_open互斥量（Mutex），在MySQL5.1和更早版本中可能就是个大问题，另外还有其他一些服务器级别的互斥量（例如查询缓存）

##### 2.3 扩展到多个CPU和核心
____

多CPU在联机事务处理（OLTP）系统的场景中非常有用。这些系统通常执行许多小的操作，并且是从多个连接发起请求，因此可以在多个CPU上运行。在这样的环境中，并发可能成为瓶颈。大多数web应用程序都属于这一类。

OLTP服务器一般使用InnoDB，尽管它在多CPU的环境中还存在一些未解决的并发问题。然而，不只是InnoDB可能成为瓶颈：任何共享资源都是潜在的竞争点。InnoDB之所以获得大量关注是因为它是高并发环境下最常见的存储引擎。但myisam在大压力时的表现也不好，即使不修改任何数据只是读取数据也是如此。许多并发瓶颈，如InnoDB的行锁和myisam的表锁，没有办法优化，除了尽可能快地处理人物之外。没有别的办法解决，这样，锁就可以尽快分配给等待的任务。如果有一个锁是造成它们都在等待的原因，那么不管有多少CPU都一样。因此，即使是一些高并发工作负载，也可以从更快的CPU中收益。

实际上有两种类型的数据库并发问题，需要不同的方法来解决

- 逻辑并发问题

    应用程序可以看到自愿的竞争，如表或者行锁争用。这些问题通常需要好的策略来解决，如改变应用程序、使用不同的存储引擎、改变服务器的配置，或使用不同的锁定提示或事务隔离级别。

- 内部并发问题

    比如信号量、访问innodb缓冲池页面的资源争用，等等。可以尝试通过改变服务器的设置、改变操作系统，或使用不同的硬件解决这些问题，但通常只能缓解而无法彻底消灭。在某些情况下，使用不同的存储引擎或给存储引擎打补丁，可以帮助缓解这些问题。

MySQL是吧的扩展模式是指它可以有效利用的CPU数量，以及在压力不断增长的情况下如何扩展，这同时取决于工作负载和系统架构。通过系统架构的手段是指通过调整操作系统和硬件，而不是通过优化使用MySQL的应用程序。CPU架构（RISC、CISC、流水线深度等）、CPU型号和操作系统都影响MySQL的扩展模式。这也是为什么说基础测试是非常重要的：一些系统可以在不断增加的并发下依然运行的很好，而另一些的表现则糟糕的多。

有些系统在更多的处理器下，甚至可能降低整体性能。这是普遍的情况，我们了解到许多人试图升级到有多个CPU的系统。最后只能被迫恢复到旧系统。因为这种升级反而降低了性能。如果规划一个大的升级必须要同时考虑硬件，服务器版本和工作负载。

现在CPU的两个复杂之处也值得提一下，首先是频率调整，这是一种电源管理技术。可以根据CPU的压力而动态的改变CPU的时钟速度。问题是他有时不能很好的处理间歇性突发的短查询的情况。因为操作系统可能需要一段时间来决定CPU的时钟是否应该变好。结果查询可能会有一段时间的速度。比较慢。并且响应时间增加了，频率调整可以能使得间歇性的工作负载性能低下，但可能更重要的是他会导致性能波动。

第二个复杂之处是boost技术。周技术改变了我们的CPU模式的看法，我们曾经以为四核2GhzCPU有四个同样强大的核心，不管其中有些闲置或非闲置。由此，一个完美的可扩展系统，当它使用所有四个内核的时候，预计可以得到四倍的提升。但是现在已经不是这样了，因为它系统只使用一个核心时。处理器和运行在更高的时钟速度上。例如3GHz。这给很多的规划容量和可扩展性建模的工具处了一个难题。因为系统性能表现不再是线性的变化了。这也意味着，空闲CPU并不代表相同规模的资源浪费。如果有一台服务器上只运行了备库的复制，复制执行是单线程的。所以有三个CPU是空闲的。因此可以认为利用这些CPU执行其他任务而不影响复制，那就错了。

#### 3 平衡内存和磁盘内置
_____

配置大量内存最大的原因不是因为可以在内存中保存大量数据，最终目的是避免磁盘IO。磁盘io比在内存中访问数据要慢的多。关键是要平衡内存和磁盘的大小，速度，成本和其他因素。以便为工作负载提供高性能的表现。

最近被使用的数据可能很快再次被使用，以及相邻的数据可能很快需要使用。这些算法非常有效，因为他们算好的空间和时间的局部性原理。

从程序员的视角看，CPU寄存器和高速缓存是透明的，并且与硬件架构相关。管理他们是编译器和CPU的工作。然而程序员会有意识的注意到内存和硬盘的不同。并且在程序中通常区分使用他们。

在数据库服务器上尤其明显。其行为往往非常符合我们刚刚提到的预测算法所做的预测。设计良好的数据会缓存，其效率通常超过操作系统的缓存。因为搜索系统缓存是为通用任务设计的，数据库库缓存，更了解数据库存取数据的需求。它包含特殊用途的逻辑，以帮助满足这些需求。此外，系统调用不需要访问数据库中的缓存数据。内存和存储是唯一可以改变的东西。

##### 3.1 随机IO和顺序IO
_____

数据库服务器同时使用顺序和随机IO。随机IO从缓存中收益最多。想象有一个典型的混合工作负载。青黄的包含单行查找和多行范围扫描。可以说服自己相信这个说法。典型的情况是热点数据随机分布。因此，缓存这些数据将有助于避免昂贵的磁盘寻道。相反，顺序读取一般只需要扫描一次数据。所以缓存对他是没用的。除非能完全放在内存中缓存起来。

顺序读取不能从缓存中受益的给另一个原因是他们比随机读快。这有以下两个原因：

- 顺序IO比随机IO块。

    顺序操作的执行速度比随机操作快，无论是在内存还是磁盘上。假设磁盘每秒可以做100个随机IO操作。并且合约完成每秒50M的顺序读取。如果每行100字节，随机读，可以每秒读100行。相比之下，顺序都可以每秒都50万行，是随机读的5000倍。或几个数量级的差异。因此，在这种情况下，随机IO可以从缓存中获得很多好处。

    顺序访问内存行的速度也快于随机访问。现在的内存芯片通常可以随机访问约25万次100字节的行。或者每秒500万次的顺序访问。请注意，内存随机访问速度比磁盘随机访问快了2500倍，而内存中顺序访问只有磁盘10倍的速度。

- 存储引擎执行顺序读比随机读块

    一个随机读一般意味着存储引擎必须执行索引操作。通常需要通过B树的数据结构查找，并且和其他值比较。相反，连续读取一般需要遍历一个简单的数据结构，例如链表。这样就减少了很多工作。反复这样操作，连续读取的速度就比随机读要快了。

最后，随机读取通常只要查找特定的行，但不仅仅只读取一行，而是要读取一整页的数据，其中大部分是不需要的。这浪费了很多工作。另一方面，顺序读取数据，通常发生在想要的页面上的所有行，所以更符合成本收益。

综上所述，通过缓存顺序读取可以节省一些工作，但缓存随机读取可以计生工作的工作。换句话说，如果能负担得起，增加内存是解决随机IO读取问题最好的办法。

##### 3.2 缓存，读和写
_____

如果有足够的内存,就可以完全避免磁盘读取请求。如果所有的数据文件都可以放在内存中，一旦服务区缓存热起来了，所有的读操作都会在缓存命中。虽然还是会有逻辑读取，不过物理读取就没有了。但写入时不同的问题。写入可以像读一样在内存中完成，但迟早要被写入到磁盘，所以它是需要持久化的。换句话说，缓存可延缓写入，但不能想消极读取一样消除写入。

事实上，除了允许写入被延迟，缓存可以允许他们被集中操作，主要通过一下两个重要途径：

- 多次写入，一次刷新

    一片数据可以在内存中改变很多次，而不需要把所有的新值写到磁盘。当数据最终被刷新到磁盘后，最后一次物理写之前发生的修改都被持久化了。例如，许多语句可以更新内存中的计数器。如果计数器递增100次，然后写到磁盘，100次修改就被合并为一次写。

- IO合并

    许多不同部分的数据可以在内存中修改，并且这些修改可以合并在一起，通过一次磁盘操作完成物理写入。

这就是为什么许多交易系统使用预写日志（WAL）策略。预写日志采用在内存中变更页面，而不马上刷新到磁盘上的策略，因为刷新磁盘通常需要随机IO,这非常慢。相反，如果把变化的记录写到一个连续的日志文件，这就很快了。后台线程可以稍后把修改的页面刷新到磁盘，并在刷新过程中优化写操作。

写入从缓存中大大受益，因为它把随机IO更多地转换到连续IO。异步写通常是由操作系统批量处理，使他们能以更优化的方式书信到磁盘。同步写必须在写入到磁盘之后才能完成。这就是为什么它们受益于RAID控制器中电池供电的回写高速缓存。

#### 3.3 工作集是什么
____

每个应用程序都有一个数据的工作集，就是做这个工作确实需要用到的数据。很多数据库都有大量不在工作集内的数据。

可以把数据库想象为有抽屉的办公桌。工作集就是放在桌面上的完成工作必须使用的文件。桌面是这个比喻中的主缓存，而抽屉就是硬盘。就像完成工作不需要办公桌里每一张纸一样，也不需要把每个数据库状态内存中来获得最佳性能，只需要工作集就可以。

工作集大小的不同取决于应用程序。对于某些应用程序工作及可能是总数据大小的1%。而对于其他应用。有可能接近百分之百。当工作集不能完全放在内存中时，数据库必须在磁盘和内存之间交换数据。已完成工作。这就是为什么内存不足，有可能看起来却像IO问题。有事没有办法把整个工作机的数据放在内存中。而并且有时也并不真的想这么做(例如，应用需要大量的顺序IO)。工作集能否完全放在内存中,对应用程序体系结构的设计会产生很大影响。

